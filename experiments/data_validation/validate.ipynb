{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\vscode_machineLearning\\internship\\Customer-Churn-Prediction\n",
      "d:\\vscode_machineLearning\\internship\\Customer-Churn-Prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('d:\\\\vscode_machineLearning\\\\internship\\\\Customer-Churn-Prediction')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'artifacts/raw_data/customer_churn_removed_col.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                             int64\n",
       "Gender                         object\n",
       "Location                       object\n",
       "Subscription_Length_Months      int64\n",
       "Monthly_Bill                  float64\n",
       "Total_Usage_GB                  int64\n",
       "Churn                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir:Path\n",
    "    data_dir:Path\n",
    "    schema_check:dict\n",
    "    make_data:dict\n",
    "    STATUS_FILE:str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churnPredictor.constants import *\n",
    "from churnPredictor.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_dirs([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.INDENPENT_FEATURES\n",
    "\n",
    "        create_dirs([config.root_dir])\n",
    "        \n",
    "\n",
    "        data_validation_config =  DataValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_dir=config.data_dir,\n",
    "            schema_check = schema,\n",
    "            make_data=config.make_data,\n",
    "            STATUS_FILE=config.status_file\n",
    "        )\n",
    "\n",
    "        return data_validation_config\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-15 15:56:24,186: INFO: utils: yaml file: schema.yaml loaded successfully]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigBox({'Age': 'int64', 'Gender': 'object', 'Location': 'object', 'Subscription_Length_Months': 'int64', 'Monthly_Bill': 'float64', 'Total_Usage_GB': 'int64'})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_yaml(SCHEMA_FILE_PATH).INDENPENT_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'Location', 'Subscription_Length_Months',\n",
       "       'Monthly_Bill', 'Total_Usage_GB', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-15 15:56:24,210: INFO: utils: yaml file: config\\config.yaml loaded successfully]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'artifacts\\\\validation\\\\train.csv'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_yaml(CONFIG_FILE_PATH).data_validation.make_data.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidataion:\n",
    "    def __init__(self,config_in :DataValidationConfig):\n",
    "        self.config_in = config_in\n",
    "\n",
    "    \n",
    "    def train_test_split_func(self):\n",
    "        df = pd.read_csv(self.config_in.data_dir)\n",
    "        train_df , test_df = train_test_split(df,test_size=0.20)\n",
    "\n",
    "        logger.info(\"Splited data into training and test sets\")\n",
    "        logger.info(train_df.shape)\n",
    "        logger.info(test_df.shape)\n",
    "\n",
    "        train_df.to_csv(self.config_in.make_data.train_data,index=False)\n",
    "        test_df.to_csv(self.config_in.make_data.test_data,index=False)\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def validate_features(self) -> bool:\n",
    "        try:\n",
    "            validation_status = False\n",
    "\n",
    "            df = self.train_test_split_func()\n",
    "            df = df.drop(columns='Churn')\n",
    "            all_features = list(df.columns)\n",
    "            all_schema = self.config_in.schema_check\n",
    "\n",
    "            for cols in all_features:\n",
    "                if cols not in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config_in.STATUS_FILE,'w') as stat_file:\n",
    "                        stat_file.write(f\"Validation status: {validation_status}\")\n",
    "                \n",
    "                else:\n",
    "                    validation_status = True\n",
    "                    with open(self.config_in.STATUS_FILE,'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "\n",
    "            logger.info(f'Validation Status is {validation_status}')\n",
    "            return validation_status\n",
    "        except Exception as e:\n",
    "            raise CustomException(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-15 15:56:24,245: INFO: utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-09-15 15:56:24,247: INFO: utils: yaml file: params.yaml loaded successfully]\n",
      "[2023-09-15 15:56:24,249: INFO: utils: yaml file: schema.yaml loaded successfully]\n",
      "[2023-09-15 15:56:24,250: INFO: utils: Created artifacts]\n",
      "[2023-09-15 15:56:24,252: INFO: utils: Created artifacts\\validation]\n",
      "[2023-09-15 15:56:24,344: INFO: 4240845019: Splited data into training and test sets]\n",
      "[2023-09-15 15:56:24,345: INFO: 4240845019: (80000, 7)]\n",
      "[2023-09-15 15:56:24,346: INFO: 4240845019: (20000, 7)]\n",
      "[2023-09-15 15:56:24,623: INFO: 4240845019: Validation Status is True]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_val_confg = config.get_data_validation_config()\n",
    "    data_validation = DataValidataion(config_in=data_val_confg)\n",
    "    data_validation.validate_features()\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
